{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81826b84",
   "metadata": {},
   "source": [
    "# Stanford RNA 3D Folding - Inference & Submission\n",
    "\n",
    "**This notebook generates predictions for the test set and creates submission.csv**\n",
    "\n",
    "Requirements:\n",
    "- Must output 5 structures per target\n",
    "- Format: ID, resname, resid, x_1, y_1, z_1, ..., x_5, y_5, z_5\n",
    "- Coordinates clipped to [-999.999, 9999.999]\n",
    "- Runtime must be < 8 hours\n",
    "- No internet access during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d64411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "DATA_DIR = '../input/stanford-rna-3d-folding-2'\n",
    "MODEL_PATH = '../input/your-model-path/model.pth'  # Update with your trained model path\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 16\n",
    "NUM_PREDICTIONS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ffdb3",
   "metadata": {},
   "source": [
    "## 1. Model Architecture (Must match training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class RNAStructurePredictor(nn.Module):\n",
    "    def __init__(self, vocab_size=5, embed_dim=256, nhead=8, num_layers=6, \n",
    "                 num_predictions=5, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_predictions = num_predictions\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=4)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=max_len)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=embed_dim * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.prediction_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(embed_dim, embed_dim // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(embed_dim // 2, 3)\n",
    "            )\n",
    "            for _ in range(num_predictions)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x_embed = self.embedding(x)\n",
    "        x_embed = self.pos_encoder(x_embed)\n",
    "        \n",
    "        padding_mask = ~mask if mask is not None else None\n",
    "        encoded = self.transformer(x_embed, src_key_padding_mask=padding_mask)\n",
    "        \n",
    "        predictions = []\n",
    "        for head in self.prediction_heads:\n",
    "            coords = head(encoded)\n",
    "            predictions.append(coords)\n",
    "        \n",
    "        predictions = torch.stack(predictions, dim=3)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc8b5f9",
   "metadata": {},
   "source": [
    "## 2. Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32554119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRNADataset(Dataset):\n",
    "    def __init__(self, data_path, max_len=512):\n",
    "        self.max_len = max_len\n",
    "        self.base2int = {'A': 0, 'C': 1, 'G': 2, 'U': 3, 'N': 4}\n",
    "        \n",
    "        # Load test sequences\n",
    "        self.seq_df = pd.read_csv(os.path.join(data_path, 'test_sequences.csv'))\n",
    "        print(f\"Loaded {len(self.seq_df)} test sequences\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seq_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.seq_df.iloc[idx]\n",
    "        target_id = row['target_id']\n",
    "        seq_str = row['sequence']\n",
    "        \n",
    "        # Convert sequence\n",
    "        seq_ids = [self.base2int.get(c, 4) for c in seq_str]\n",
    "        orig_len = min(len(seq_ids), self.max_len)\n",
    "        \n",
    "        # Truncate or pad\n",
    "        if len(seq_ids) > self.max_len:\n",
    "            seq_ids = seq_ids[:self.max_len]\n",
    "        else:\n",
    "            seq_ids = seq_ids + [4] * (self.max_len - len(seq_ids))\n",
    "        \n",
    "        input_ids = torch.tensor(seq_ids, dtype=torch.long)\n",
    "        mask = torch.zeros(self.max_len, dtype=torch.bool)\n",
    "        mask[:orig_len] = True\n",
    "        \n",
    "        return input_ids, mask, target_id, orig_len, seq_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03293633",
   "metadata": {},
   "source": [
    "## 3. Load Model and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "config = checkpoint.get('config', {})\n",
    "\n",
    "model = RNAStructurePredictor(\n",
    "    vocab_size=5,\n",
    "    embed_dim=config.get('embed_dim', 256),\n",
    "    nhead=config.get('nhead', 8),\n",
    "    num_layers=config.get('num_layers', 6),\n",
    "    num_predictions=NUM_PREDICTIONS,\n",
    "    dropout=config.get('dropout', 0.1),\n",
    "    max_len=MAX_LEN\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset\n",
    "test_dataset = TestRNADataset(DATA_DIR, max_len=MAX_LEN)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Inference\"):\n",
    "        input_ids, mask, target_ids, orig_lens, sequences = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        mask = mask.to(device)\n",
    "        \n",
    "        # Get predictions: (batch, seq_len, 3, num_predictions)\n",
    "        predictions = model(input_ids, mask)\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        \n",
    "        # Process each sequence in batch\n",
    "        for i in range(len(target_ids)):\n",
    "            target_id = target_ids[i]\n",
    "            orig_len = orig_lens[i].item()\n",
    "            sequence = sequences[i]\n",
    "            \n",
    "            # Get predictions for this sequence (only valid positions)\n",
    "            coords = predictions[i, :orig_len, :, :]  # (orig_len, 3, num_predictions)\n",
    "            \n",
    "            # Clip coordinates to competition limits\n",
    "            coords = np.clip(coords, -999.999, 9999.999)\n",
    "            \n",
    "            # Store for submission creation\n",
    "            all_predictions.append({\n",
    "                'target_id': target_id,\n",
    "                'sequence': sequence,\n",
    "                'coords': coords  # (orig_len, 3, 5)\n",
    "            })\n",
    "\n",
    "print(f\"Generated predictions for {len(all_predictions)} targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5eacb7",
   "metadata": {},
   "source": [
    "## 4. Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9976f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample submission to get the correct format\n",
    "sample_sub = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'))\n",
    "print(f\"Sample submission shape: {sample_sub.shape}\")\n",
    "print(f\"Sample submission columns: {sample_sub.columns.tolist()}\")\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_rows = []\n",
    "\n",
    "for pred_dict in tqdm(all_predictions, desc=\"Creating submission\"):\n",
    "    target_id = pred_dict['target_id']\n",
    "    sequence = pred_dict['sequence']\n",
    "    coords = pred_dict['coords']  # (seq_len, 3, 5)\n",
    "    \n",
    "    for resid in range(len(sequence)):\n",
    "        resname = sequence[resid]\n",
    "        \n",
    "        # Create row with ID, resname, resid, and all 5 predictions\n",
    "        row = {\n",
    "            'ID': f\"{target_id}_{resid + 1}\",  # 1-indexed\n",
    "            'resname': resname,\n",
    "            'resid': resid + 1\n",
    "        }\n",
    "        \n",
    "        # Add coordinates for all 5 predictions\n",
    "        for pred_idx in range(NUM_PREDICTIONS):\n",
    "            x, y, z = coords[resid, :, pred_idx]\n",
    "            row[f'x_{pred_idx + 1}'] = x\n",
    "            row[f'y_{pred_idx + 1}'] = y\n",
    "            row[f'z_{pred_idx + 1}'] = z\n",
    "        \n",
    "        submission_rows.append(row)\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "print(f\"\\nSubmission shape: {submission_df.shape}\")\n",
    "print(f\"Submission columns: {submission_df.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify submission format\n",
    "required_cols = ['ID', 'resname', 'resid']\n",
    "for i in range(1, NUM_PREDICTIONS + 1):\n",
    "    required_cols.extend([f'x_{i}', f'y_{i}', f'z_{i}'])\n",
    "\n",
    "print(\"\\nVerifying submission format...\")\n",
    "assert list(submission_df.columns) == required_cols, \"Column mismatch!\"\n",
    "assert len(submission_df) == len(sample_sub), f\"Row count mismatch! Expected {len(sample_sub)}, got {len(submission_df)}\"\n",
    "print(\"✓ Format verification passed!\")\n",
    "\n",
    "# Check for NaN values\n",
    "nan_count = submission_df.isna().sum().sum()\n",
    "if nan_count > 0:\n",
    "    print(f\"WARNING: Found {nan_count} NaN values. Filling with 0.\")\n",
    "    submission_df = submission_df.fillna(0.0)\n",
    "\n",
    "# Check coordinate ranges\n",
    "coord_cols = [col for col in submission_df.columns if col.startswith(('x_', 'y_', 'z_'))]\n",
    "coord_min = submission_df[coord_cols].min().min()\n",
    "coord_max = submission_df[coord_cols].max().max()\n",
    "print(f\"\\nCoordinate range: [{coord_min:.3f}, {coord_max:.3f}]\")\n",
    "assert coord_min >= -999.999 and coord_max <= 9999.999, \"Coordinates out of range!\"\n",
    "print(\"✓ Coordinate range check passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd396c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Submission file created successfully!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"File: submission.csv\")\n",
    "print(f\"Shape: {submission_df.shape}\")\n",
    "print(f\"Size: {os.path.getsize('submission.csv') / 1e6:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

[{"stream_name":"stderr","time":7.616213874,"data":"0.00s - Debugger warning: It seems that frozen modules are being used, which may\n"}
,{"stream_name":"stderr","time":7.616273608,"data":"0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n"}
,{"stream_name":"stderr","time":7.6162778840000005,"data":"0.00s - to python to disable frozen modules.\n"}
,{"stream_name":"stderr","time":7.616280321,"data":"0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"}
,{"stream_name":"stderr","time":8.252102077,"data":"0.00s - Debugger warning: It seems that frozen modules are being used, which may\n"}
,{"stream_name":"stderr","time":8.252136821,"data":"0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n"}
,{"stream_name":"stderr","time":8.252141135,"data":"0.00s - to python to disable frozen modules.\n"}
,{"stream_name":"stderr","time":8.252143923,"data":"0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"}
,{"stream_name":"stdout","time":13.973493568,"data":"[12:04:43] Starting inference...\n"}
,{"stream_name":"stdout","time":13.973540349,"data":"Device: cuda\n"}
,{"stream_name":"stdout","time":13.973544998,"data":"GPU: Tesla P100-PCIE-16GB\n"}
,{"stream_name":"stdout","time":13.985142421,"data":"Config loaded\n"}
,{"stream_name":"stdout","time":13.985165372,"data":"Normalization - Mean: [158.24141 156.78705 154.46898], Std: [131.6201  132.98083 127.77188]\n"}
,{"stream_name":"stdout","time":14.000254258,"data":"Model class defined\n"}
,{"stream_name":"stdout","time":14.144623254,"data":"[12:04:43] Loading model...\n"}
,{"stream_name":"stderr","time":14.314347473,"data":"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n"}
,{"stream_name":"stderr","time":14.314382515,"data":"  warnings.warn(\n"}
,{"stream_name":"stderr","time":14.314387728,"data":"\n"}
,{"stream_name":"stderr","time":14.314392166,"data":"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n"}
,{"stream_name":"stderr","time":14.314396823,"data":"  warnings.warn(\n"}
,{"stream_name":"stdout","time":14.328861341,"data":"Loading from: ../input/stanford-rna-3d-folding-starter/model.pth\n"}
,{"stream_name":"stdout","time":14.32888768,"data":"Path exists: True\n"}
,{"stream_name":"stdout","time":14.32889343,"data":"Available files: ['../input/stanford-rna-3d-folding-starter/model.pth', '../input/stanford-rna-3d-folding-starter/__results__.html', '../input/stanford-rna-3d-folding-starter/__notebook__.ipynb', '../input/stanford-rna-3d-folding-starter/__output__.json', '../input/stanford-rna-3d-folding-starter/custom.css']\n"}
,{"stream_name":"stdout","time":14.32890117,"data":"Checkpoint type: \u003cclass 'collections.OrderedDict'\u003e\n"}
,{"stream_name":"stdout","time":14.32890749,"data":"Checkpoint keys: odict_keys(['embedding.weight', 'transformer.layers.0.self_attn.in_proj_weight', 'transformer.layers.0.self_attn.in_proj_bias', 'transformer.layers.0.self_attn.out_proj.weight', 'transformer.layers.0.self_attn.out_proj.bias', 'transformer.layers.0.linear1.weight', 'transformer.layers.0.linear1.bias', 'transformer.layers.0.linear2.weight', 'transformer.layers.0.linear2.bias', 'transformer.layers.0.norm1.weight', 'transformer.layers.0.norm1.bias', 'transformer.layers.0.norm2.weight', 'transformer.layers.0.norm2.bias', 'transformer.layers.1.self_attn.in_proj_weight', 'transformer.layers.1.self_attn.in_proj_bias', 'transformer.layers.1.self_attn.out_proj.weight', 'transformer.layers.1.self_attn.out_proj.bias', 'transformer.layers.1.linear1.weight', 'transformer.layers.1.linear1.bias', 'transformer.layers.1.linear2.weight', 'transformer.layers.1.linear2.bias', 'transformer.layers.1.norm1.weight', 'transformer.layers.1.norm1.bias', 'transformer.layers.1.norm2.weight', 'transformer.layers.1.norm2.bias', 'transformer.layers.2.self_attn.in_proj_weight', 'transformer.layers.2.self_attn.in_proj_bias', 'transformer.layers.2.self_attn.out_proj.weight', 'transformer.layers.2.self_attn.out_proj.bias', 'transformer.layers.2.linear1.weight', 'transformer.layers.2.linear1.bias', 'transformer.layers.2.linear2.weight', 'transformer.layers.2.linear2.bias', 'transformer.layers.2.norm1.weight', 'transformer.layers.2.norm1.bias', 'transformer.layers.2.norm2.weight', 'transformer.layers.2.norm2.bias', 'transformer.layers.3.self_attn.in_proj_weight', 'transformer.layers.3.self_attn.in_proj_bias', 'transformer.layers.3.self_attn.out_proj.weight', 'transformer.layers.3.self_attn.out_proj.bias', 'transformer.layers.3.linear1.weight', 'transformer.layers.3.linear1.bias', 'transformer.layers.3.linear2.weight', 'transformer.layers.3.linear2.bias', 'transformer.layers.3.norm1.weight', 'transformer.layers.3.norm1.bias', 'transformer.layers.3.norm2.weight', 'transformer.layers.3.norm2.bias', 'fc.weight', 'fc.bias'])\n"}
,{"stream_name":"stderr","time":16.821004113,"data":"Traceback (most recent call last):\n"}
,{"stream_name":"stderr","time":16.821028567,"data":"  File \"\u003cstring\u003e\", line 1, in \u003cmodule\u003e\n"}
,{"stream_name":"stderr","time":16.821034701,"data":"  File \"/usr/local/lib/python3.12/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n"}
,{"stream_name":"stderr","time":16.821081198,"data":"    raise_for_execution_errors(nb, output_path)\n"}
,{"stream_name":"stderr","time":16.821119835,"data":"  File \"/usr/local/lib/python3.12/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n"}
,{"stream_name":"stderr","time":16.821276107,"data":"    raise error\n"}
,{"stream_name":"stderr","time":16.821592068,"data":"papermill.exceptions.PapermillExecutionError: \n"}
,{"stream_name":"stderr","time":16.821607526,"data":"---------------------------------------------------------------------------\n"}
,{"stream_name":"stderr","time":16.821611744,"data":"Exception encountered at \"In [4]\":\n"}
,{"stream_name":"stderr","time":16.821615303,"data":"---------------------------------------------------------------------------\n"}
,{"stream_name":"stderr","time":16.821618907,"data":"RuntimeError                              Traceback (most recent call last)\n"}
,{"stream_name":"stderr","time":16.821622446,"data":"/tmp/ipykernel_24/3547828454.py in \u003ccell line: 0\u003e()\n"}
,{"stream_name":"stderr","time":16.821626168,"data":"     32 elif isinstance(ckpt, dict):\n"}
,{"stream_name":"stderr","time":16.821629486,"data":"     33     # Maybe it's just the state dict directly\n"}
,{"stream_name":"stderr","time":16.821632984,"data":"---\u003e 34     model.load_state_dict(ckpt)\n"}
,{"stream_name":"stderr","time":16.821636365,"data":"     35 else:\n"}
,{"stream_name":"stderr","time":16.821639731,"data":"     36     raise ValueError(f\"Unknown checkpoint format: {type(ckpt)}\")\n"}
,{"stream_name":"stderr","time":16.821643192,"data":"\n"}
,{"stream_name":"stderr","time":16.821646447,"data":"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py in load_state_dict(self, state_dict, strict, assign)\n"}
,{"stream_name":"stderr","time":16.821650784,"data":"   2622 \n"}
,{"stream_name":"stderr","time":16.821654779,"data":"   2623         if len(error_msgs) \u003e 0:\n"}
,{"stream_name":"stderr","time":16.821658964,"data":"-\u003e 2624             raise RuntimeError(\n"}
,{"stream_name":"stderr","time":16.821679618,"data":"   2625                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n"}
,{"stream_name":"stderr","time":16.821683799,"data":"   2626                     self.__class__.__name__, \"\\n\\t\".join(error_msgs)\n"}
,{"stream_name":"stderr","time":16.821687527,"data":"\n"}
,{"stream_name":"stderr","time":16.821690654,"data":"RuntimeError: Error(s) in loading state_dict for RNAStructurePredictor:\n"}
,{"stream_name":"stderr","time":16.821695642,"data":"\tMissing key(s) in state_dict: \"pos_encoder.pe\", \"transformer.layers.4.self_attn.in_proj_weight\", \"transformer.layers.4.self_attn.in_proj_bias\", \"transformer.layers.4.self_attn.out_proj.weight\", \"transformer.layers.4.self_attn.out_proj.bias\", \"transformer.layers.4.linear1.weight\", \"transformer.layers.4.linear1.bias\", \"transformer.layers.4.linear2.weight\", \"transformer.layers.4.linear2.bias\", \"transformer.layers.4.norm1.weight\", \"transformer.layers.4.norm1.bias\", \"transformer.layers.4.norm2.weight\", \"transformer.layers.4.norm2.bias\", \"transformer.layers.5.self_attn.in_proj_weight\", \"transformer.layers.5.self_attn.in_proj_bias\", \"transformer.layers.5.self_attn.out_proj.weight\", \"transformer.layers.5.self_attn.out_proj.bias\", \"transformer.layers.5.linear1.weight\", \"transformer.layers.5.linear1.bias\", \"transformer.layers.5.linear2.weight\", \"transformer.layers.5.linear2.bias\", \"transformer.layers.5.norm1.weight\", \"transformer.layers.5.norm1.bias\", \"transformer.layers.5.norm2.weight\", \"transformer.layers.5.norm2.bias\", \"prediction_heads.0.0.weight\", \"prediction_heads.0.0.bias\", \"prediction_heads.0.3.weight\", \"prediction_heads.0.3.bias\", \"prediction_heads.0.5.weight\", \"prediction_heads.0.5.bias\", \"prediction_heads.1.0.weight\", \"prediction_heads.1.0.bias\", \"prediction_heads.1.3.weight\", \"prediction_heads.1.3.bias\", \"prediction_heads.1.5.weight\", \"prediction_heads.1.5.bias\", \"prediction_heads.2.0.weight\", \"prediction_heads.2.0.bias\", \"prediction_heads.2.3.weight\", \"prediction_heads.2.3.bias\", \"prediction_heads.2.5.weight\", \"prediction_heads.2.5.bias\", \"prediction_heads.3.0.weight\", \"prediction_heads.3.0.bias\", \"prediction_heads.3.3.weight\", \"prediction_heads.3.3.bias\", \"prediction_heads.3.5.weight\", \"prediction_heads.3.5.bias\", \"prediction_heads.4.0.weight\", \"prediction_heads.4.0.bias\", \"prediction_heads.4.3.weight\", \"prediction_heads.4.3.bias\", \"prediction_heads.4.5.weight\", \"prediction_heads.4.5.bias\". \n"}
,{"stream_name":"stderr","time":16.821715972,"data":"\tUnexpected key(s) in state_dict: \"fc.weight\", \"fc.bias\". \n"}
,{"stream_name":"stderr","time":16.821719829,"data":"\tsize mismatch for embedding.weight: copying a param with shape torch.Size([5, 128]) from checkpoint, the shape in current model is torch.Size([5, 256]).\n"}
,{"stream_name":"stderr","time":16.821725509,"data":"\tsize mismatch for transformer.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n"}
,{"stream_name":"stderr","time":16.821729091999998,"data":"\tsize mismatch for transformer.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n"}
,{"stream_name":"stderr","time":16.821733305,"data":"\tsize mismatch for transformer.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n"}
,{"stream_name":"stderr","time":16.821740206,"data":"\tsize mismatch for transformer.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821743868,"data":"\tsize mismatch for transformer.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n"}
,{"stream_name":"stderr","time":16.821756712,"data":"\tsize mismatch for transformer.layers.0.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n"}
,{"stream_name":"stderr","time":16.821761867,"data":"\tsize mismatch for transformer.layers.0.linear2.weight: copying a param with shape torch.Size([128, 2048]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n"}
,{"stream_name":"stderr","time":16.821765952,"data":"\tsize mismatch for transformer.layers.0.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821769587,"data":"\tsize mismatch for transformer.layers.0.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821773436,"data":"\tsize mismatch for transformer.layers.0.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821777142,"data":"\tsize mismatch for transformer.layers.0.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821781034,"data":"\tsize mismatch for transformer.layers.0.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821784697,"data":"\tsize mismatch for transformer.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n"}
,{"stream_name":"stderr","time":16.821788534,"data":"\tsize mismatch for transformer.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n"}
,{"stream_name":"stderr","time":16.821792306,"data":"\tsize mismatch for transformer.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n"}
,{"stream_name":"stderr","time":16.821796107,"data":"\tsize mismatch for transformer.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821799824,"data":"\tsize mismatch for transformer.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n"}
,{"stream_name":"stderr","time":16.821804029,"data":"\tsize mismatch for transformer.layers.1.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n"}
,{"stream_name":"stderr","time":16.821807773,"data":"\tsize mismatch for transformer.layers.1.linear2.weight: copying a param with shape torch.Size([128, 2048]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n"}
,{"stream_name":"stderr","time":16.821811498,"data":"\tsize mismatch for transformer.layers.1.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821815202,"data":"\tsize mismatch for transformer.layers.1.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821826607,"data":"\tsize mismatch for transformer.layers.1.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821830101,"data":"\tsize mismatch for transformer.layers.1.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821835636,"data":"\tsize mismatch for transformer.layers.1.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821839449,"data":"\tsize mismatch for transformer.layers.2.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n"}
,{"stream_name":"stderr","time":16.82184392,"data":"\tsize mismatch for transformer.layers.2.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n"}
,{"stream_name":"stderr","time":16.821849118,"data":"\tsize mismatch for transformer.layers.2.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n"}
,{"stream_name":"stderr","time":16.82185373,"data":"\tsize mismatch for transformer.layers.2.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821858931,"data":"\tsize mismatch for transformer.layers.2.linear1.weight: copying a param with shape torch.Size([2048, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n"}
,{"stream_name":"stderr","time":16.821862841,"data":"\tsize mismatch for transformer.layers.2.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n"}
,{"stream_name":"stderr","time":16.821866672,"data":"\tsize mismatch for transformer.layers.2.linear2.weight: copying a param with shape torch.Size([128, 2048]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n"}
,{"stream_name":"stderr","time":16.821870447,"data":"\tsize mismatch for transformer.layers.2.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821874149,"data":"\tsize mismatch for transformer.layers.2.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821877851,"data":"\tsize mismatch for transformer.layers.2.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821881546,"data":"\tsize mismatch for transformer.layers.2.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821885288,"data":"\tsize mismatch for transformer.layers.2.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821888932,"data":"\tsize mismatch for transformer.layers.3.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n"}
,{"stream_name":"stderr","time":16.821892658,"data":"\tsize mismatch for transformer.layers.3.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n"}
,{"stream_name":"stderr","time":16.821902684,"data":"\tsize mismatch for transformer.layers.3.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n"}
,{"stream_name":"stderr","time":16.821906589,"data":"\tsize mismatch for transformer.layers.3.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821910784,"data":"\tsize mismatch for transformer.layers.3.linear1.weight: copying a param with shape torch.Size([2048, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n"}
,{"stream_name":"stderr","time":16.821915647,"data":"\tsize mismatch for transformer.layers.3.linear1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n"}
,{"stream_name":"stderr","time":16.821921114,"data":"\tsize mismatch for transformer.layers.3.linear2.weight: copying a param with shape torch.Size([128, 2048]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n"}
,{"stream_name":"stderr","time":16.821924894,"data":"\tsize mismatch for transformer.layers.3.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821928723,"data":"\tsize mismatch for transformer.layers.3.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821934274,"data":"\tsize mismatch for transformer.layers.3.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821938139,"data":"\tsize mismatch for transformer.layers.3.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821942556,"data":"\tsize mismatch for transformer.layers.3.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"}
,{"stream_name":"stderr","time":16.821947277,"data":"\n"}
,{"stream_name":"stderr","time":18.872014099,"data":"/usr/local/lib/python3.12/dist-packages/mistune.py:435: SyntaxWarning: invalid escape sequence '\\|'\n"}
,{"stream_name":"stderr","time":18.872047608,"data":"  cells[i][c] = re.sub('\\\\\\\\\\|', '|', cell)\n"}
,{"stream_name":"stderr","time":19.018630981,"data":"/usr/local/lib/python3.12/dist-packages/nbconvert/filters/filter_links.py:36: SyntaxWarning: invalid escape sequence '\\_'\n"}
,{"stream_name":"stderr","time":19.018659386,"data":"  text = re.sub(r'_', '\\_', text) # Escape underscores in display text\n"}
,{"stream_name":"stderr","time":19.683226943,"data":"/usr/local/lib/python3.12/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=[\"remove_papermill_header.RemovePapermillHeader\"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.\n"}
,{"stream_name":"stderr","time":19.683258312,"data":"  warn(\n"}
,{"stream_name":"stderr","time":19.717687506,"data":"[NbConvertApp] Converting notebook __notebook__.ipynb to notebook\n"}
,{"stream_name":"stderr","time":20.017331915,"data":"[NbConvertApp] Writing 42217 bytes to __notebook__.ipynb\n"}
,{"stream_name":"stderr","time":22.525641566,"data":"/usr/local/lib/python3.12/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=[\"nbconvert.preprocessors.ExtractOutputPreprocessor\"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.\n"}
,{"stream_name":"stderr","time":22.525689573,"data":"  warn(\n"}
,{"stream_name":"stderr","time":22.550459996,"data":"[NbConvertApp] Converting notebook __notebook__.ipynb to html\n"}
,{"stream_name":"stderr","time":23.357227348,"data":"[NbConvertApp] Writing 340216 bytes to __results__.html\n"}
]